{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a0cb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langsmith import Client\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2365138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "import json\n",
    "\n",
    "with open('output.json', 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# reformatting the keys and make up content to store\n",
    "documents = []\n",
    "for item in raw_data:\n",
    "    cleaned_item = {}\n",
    "    for key, value in item.items():\n",
    "        if not value: continue\n",
    "        k = key.lower().strip()\n",
    "\n",
    "        if \"research\" in k:\n",
    "            target_key = \"research\"\n",
    "        elif any(x in k for x in [\"publications\", \"books\", \"project\", \"patents\"]):\n",
    "            target_key = \"publications\"\n",
    "        elif any(x in k for x in [\"courses\", \"lectures\"]):\n",
    "            target_key = \"courses\"\n",
    "        elif any(x in k for x in [\"teaching\", \"students\", \"classroom\"]):\n",
    "            target_key = \"teaching\"\n",
    "        elif \"experience\" in k:\n",
    "            target_key = \"experience\"\n",
    "        elif \"website\" in k:\n",
    "            target_key = \"website\"\n",
    "        elif \"news\" in k:\n",
    "            target_key = \"news\"\n",
    "        elif k in [\"positions\", \"position\"]:\n",
    "            target_key = \"position\"\n",
    "        else:\n",
    "            target_key = k\n",
    "        if target_key in cleaned_item:\n",
    "            if value not in cleaned_item[target_key]:\n",
    "                cleaned_item[target_key] += \"\\n\" + value\n",
    "        else:\n",
    "            cleaned_item[target_key] = value\n",
    "\n",
    "    search_parts = [\n",
    "        f\"Research & Expertise: {cleaned_item.get('research', '')}\",\n",
    "        f\"Publications & Works: {cleaned_item.get('publications', '')}\",\n",
    "        f\"Biography: {cleaned_item.get('biography', '')}\",\n",
    "        f\"Experience: {cleaned_item.get('experience', '')}\",\n",
    "        f\"Courses & Teaching: {cleaned_item.get('courses', '')} {cleaned_item.get('teaching', '')}\"\n",
    "    ]\n",
    "\n",
    "    full_search_text = \"\\n\".join([p for p in search_parts if len(p) > 25])\n",
    "\n",
    "    metadata = {\n",
    "        \"name\": cleaned_item.get(\"name\"),\n",
    "        \"position\": cleaned_item.get(\"position\"),\n",
    "        \"department\": cleaned_item.get(\"departments\"),\n",
    "        \"contact\": cleaned_item.get(\"contact\"),\n",
    "        \"website\": cleaned_item.get(\"website\")\n",
    "    }\n",
    "    if full_search_text.strip():\n",
    "        doc = Document(page_content=full_search_text, metadata=metadata)\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26715e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6221c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "# vector_db = QdrantVectorStore.from_documents(\n",
    "#     documents,\n",
    "#     embeddings,\n",
    "#     path=\"./qdrant_db\",  \n",
    "#     collection_name=\"nu_professors\",\n",
    "# )\n",
    "vector_db = QdrantVectorStore.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    location=\":memory:\",  # 不写磁盘，绕过文件锁\n",
    "    collection_name=\"nu_professors\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62531d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free version\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# vector_db = QdrantVectorStore.from_documents(\n",
    "#     documents,\n",
    "#     embeddings,\n",
    "#     location=\":memory:\", \n",
    "#     collection_name=\"nu_professors\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab720d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define retriever and llm\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41e514d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query reconstruction\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_queries = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generated_queries = prompt_queries | llm | StrOutputParser() | (lambda x: x.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "776d6fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "retrieval_chain = generated_queries | retriever.map() | get_unique_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        f\"Name: {d.metadata.get('name')}\\n\"\n",
    "        f\"Dept: {d.metadata.get('department')}\\n\"\n",
    "        f\"Contact: {d.metadata.get('contact')}\\n\"\n",
    "        f\"Position: {d.metadata.get('position', '')}\\n\"\n",
    "        f\"Website: {d.metadata.get('website', '')}\\n\"\n",
    "        f\"Related Content: {d.page_content}\"\n",
    "        for d in docs\n",
    "    )\n",
    "\n",
    "system_content = \"\"\"You are an expert academic research assistant specializing in the faculty of Northwestern University's McCormick School of Engineering.\n",
    "\n",
    "Your goal is to help users find the most relevant professors based on the provided context. \n",
    "\n",
    "Guidelines:\n",
    "1. **Identify Professors**: The context contains faculty names, departments, and research interests. Always mention the professor's name clearly.\n",
    "2. **Handle Technical Terms**: If a user asks about a specific term like 'RAG', search the context for related fields like 'Natural Language Processing', 'Information Retrieval', or 'Artificial Intelligence' if a direct match isn't found.\n",
    "3. **Be Specific**: Mention the department or specific lab if available.\n",
    "4. **Admit Ignorance**: If the context does not contain information about a professor doing that specific research, explicitly state: \"Based on the current database, no professor was found specifically researching [Topic].\" Do not hallucinate or list irrelevant professors.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_content),\n",
    "    (\"human\", \"Context:\\n{context}\\n\\nQuestion: {question}\")\n",
    "])\n",
    "rag_chain = (\n",
    "    {\"context\": retrieval_chain | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "983a79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain_core._api import LangChainBetaWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=LangChainBetaWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba4d5581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the current database, the best professor to reach out to for research in distributed systems, who is known to be friendly and patient with starters, would be **Peter Dinda**. Professor Dinda specializes in experimental computer systems, particularly parallel and distributed systems. His research involves virtualization and operating systems for distributed and parallel computing, making him a suitable choice for your research interests. You can find more information about him on his website at [Peter Dinda's Homepage](http://pdinda.org/).\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"Who should I reach out to if I want to do research in distributed system? I want the professor to be friendly and patient to starter\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
